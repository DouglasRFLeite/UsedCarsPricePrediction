{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My First Machine Learning Algorithm\n",
    "### And maybe yoursÂ too\n",
    "\n",
    "Hi! I'm Douglas and I'm a Data Science enthusiast trying to learn everything I think I need to become a Data Scientist.\n",
    "\n",
    "I took a small step outside my studying plans and did a very quick Kaggle course on [**Intro to Machine Learning**](https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Flearn%2Fintro-to-machine-learning). There they use the famous housing prices example with both Melbourn and Iowa data and guide you through creating **your first regression model** with the Decision Tree and Random Forest algorithms.\n",
    "\n",
    "![Kaggle Completion Certificate](img/certificate.png)\n",
    "\n",
    "Well, if you read my [**About me**](https://medium.com/@douglas.rochedo/about-me-989738f3fae3) post you know this isn't really my first machine learning algorithm, I actually have a bit of experience with machine learning. But this is my first time using Decision Tree and Random Forest algorithms and it might as well be your first algorithm ever, so let's get right into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "For this tutorial-ish article, I chose not to use the same housing prices dataset used in the Kaggle course. Instead, I went on Kaggle itself and chose a [**Used Car Prices Prediction dataset**](https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fvijayaadithyanvg%2Fcar-price-predictionused-cars), a pretty new one I might say. To take a quick look into it we are going to use the Pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Present_Price</th>\n",
       "      <th>Driven_kms</th>\n",
       "      <th>Fuel_Type</th>\n",
       "      <th>Selling_type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ritz</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.35</td>\n",
       "      <td>5.59</td>\n",
       "      <td>27000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sx4</td>\n",
       "      <td>2013</td>\n",
       "      <td>4.75</td>\n",
       "      <td>9.54</td>\n",
       "      <td>43000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2017</td>\n",
       "      <td>7.25</td>\n",
       "      <td>9.85</td>\n",
       "      <td>6900</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wagon r</td>\n",
       "      <td>2011</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.15</td>\n",
       "      <td>5200</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swift</td>\n",
       "      <td>2014</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.87</td>\n",
       "      <td>42450</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Dealer</td>\n",
       "      <td>Manual</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Car_Name  Year  Selling_Price  Present_Price  Driven_kms Fuel_Type  \\\n",
       "0     ritz  2014           3.35           5.59       27000    Petrol   \n",
       "1      sx4  2013           4.75           9.54       43000    Diesel   \n",
       "2     ciaz  2017           7.25           9.85        6900    Petrol   \n",
       "3  wagon r  2011           2.85           4.15        5200    Petrol   \n",
       "4    swift  2014           4.60           6.87       42450    Diesel   \n",
       "\n",
       "  Selling_type Transmission  Owner  \n",
       "0       Dealer       Manual      0  \n",
       "1       Dealer       Manual      0  \n",
       "2       Dealer       Manual      0  \n",
       "3       Dealer       Manual      0  \n",
       "4       Dealer       Manual      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"car data.csv\")\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we see the shape of our dataset: 301 rows and 9 columns. Each one of those rows represent an used car, and each of those columns represent a feature from those cars. We see we have numerical features (Year, Selling_Price, Present_Price, Driven_kms and Owner) and categorical features (Car_Name, Fuel_Type, Selling_Type and Transmission).\n",
    "\n",
    "The purpose of this article is not to engange in the matters of Data Cleaning or Data Wrangling. But hence this is not a dataset create with the purpose of being used in a tutorial, it might (and does) have some small problemns we might want to solve. And that, very fortunetly, are pretty easy to solve. First of all we check for null (or, rather, missing) values in our datset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car_Name         0\n",
       "Year             0\n",
       "Selling_Price    0\n",
       "Present_Price    0\n",
       "Driven_kms       0\n",
       "Fuel_Type        0\n",
       "Selling_type     0\n",
       "Transmission     0\n",
       "Owner            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That asures us that in no column is there an empty or missing value. That is definetly a relief.\n",
    "\n",
    "Further on, we check for duplicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two duplicates means we have 2 cars in our dataset that are, each one, equal to some other car (not necessarily equal to one another). That will be a problemn if it comes to affect the trainig of our model. Thus, we are going to drop those duplicates and reasure the there are no other ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(299, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset.drop_duplicates(inplace=True)\n",
    "print(dataset.duplicated().sum())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have now 2 less cars in our dataset, but that is good because now each observation is completly singular. \n",
    "\n",
    "### Creating our first Decision Tree\n",
    "\n",
    "So, to create, train and test a Decision Tree (or any Machine Learning Model, for that matter) we first need to know what we want to predict and what features we will use to try and predict it. In this case, I want to predict the Present Price of the used car and thus I save that single column in what would be a labels table called y.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    5.59\n",
       "1    9.54\n",
       "2    9.85\n",
       "3    4.15\n",
       "4    6.87\n",
       "Name: Present_Price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['Present_Price']\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order to decide which features we will use, I've used a simple decisive factor: we will not engineer features. With that I mean that, since Decision Trees, even though they should, do not handle categorical data (or, at least, the one we are using, from Scikit-learn doesn't) we will dump categorical features from our model. In other words, the only features we are going to use are the numerical ones: Year, Selling price, Driven kilometers and owner, which is actually categorical, but also numerical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Selling_Price</th>\n",
       "      <th>Driven_kms</th>\n",
       "      <th>Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>3.35</td>\n",
       "      <td>27000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>4.75</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.25</td>\n",
       "      <td>6900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>2.85</td>\n",
       "      <td>5200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>4.60</td>\n",
       "      <td>42450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Selling_Price  Driven_kms  Owner\n",
       "0  2014           3.35       27000      0\n",
       "1  2013           4.75       43000      0\n",
       "2  2017           7.25        6900      0\n",
       "3  2011           2.85        5200      0\n",
       "4  2014           4.60       42450      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[[\"Year\", \"Selling_Price\", \"Driven_kms\", \"Owner\"]]\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To later on evaluate our model with data it has not seen before, we wil use Scikit-learns train-test splitter function to have a randomized split between data to train the model and data to test it later. We will set a random state to it with the number 7 so it runs exactly the same every time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to actually create our model once and for all, we will use a Scikit-learns class that runs a Decision Tree for Regression (finding continuous values) called, naturally, DecisionTreeRegressor. We will than fit it - or train it, as you wish - with the training data. At last, we will predict the labels for the X_test data and compare it to the actual labels for those cars, calculating the mean absolute error of that comparison so we can have an idea of how well (or poorly) our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6693333333333331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "default_DT = DecisionTreeRegressor(random_state=7)\n",
    "default_DT.fit(X_train, y_train)\n",
    "mae_df = mean_absolute_error(y_test, default_DT.predict(X_test))\n",
    "print(mae_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing an error of merly 1.67 leads us into thinking this is a fantastic model. But, if we analyze the data we will see that that number is not far from the average of the labes we want to predict, that is, the present price of the cars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.541036789297662\n",
      "22.14 %\n"
     ]
    }
   ],
   "source": [
    "average_present_price = y.mean()\n",
    "print(average_present_price)\n",
    "\n",
    "relative_error = round(mae_df/average_present_price *100, 2)\n",
    "print(relative_error, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, that error actually means a 22.14% average error in the predictions for that dataset. Is it enough? It depends on the scenario, how much time and money one can spend to further improve this model and far more other factors. In our case, we still want to improve it by as much as we can (or at least for as much as this Kaggle course has taught us to).\n",
    "\n",
    "### Tuning the Parameters\n",
    "\n",
    "Yes, I am aware the corect name is hyperparameters, but Kaggle did not get into that matter so neither will I. If you are unfamiliar, the parameters we are talking about are some characteristics of the Decision Tree that can interfere with its performance. We will not talk much about Overfiting or Underfiting here, but those two scenarios can happen and often worse the models performance. In the case of Decision Trees, one parameter we can adjust to improve the overall performance by fleeing from these problmens is the maximum number of leafs. Increasing the number of leafs will lead the model to fit to much the training data and perform poorly on other data such as the test data. On the other hand, if we have only a small number of leaves, it will not fit our data at all and perform pooly on train and test data alike. \n",
    "\n",
    "So, to try and solve that problemn and find out if it really is what is hurting our models performance, we shall test a few possibilities for the maximum number of leafs and chose the one with the best performance, or the smaller mean absolute error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Leafs: 5 | MAE: 2.3890808214008215\n",
      "Max Leafs: 10 | MAE: 2.5523355559075074\n",
      "Max Leafs: 50 | MAE: 1.6066773766058149\n",
      "Max Leafs: 100 | MAE: 1.6366038095238098\n",
      "Max Leafs: 500 | MAE: 1.6527999999999998\n",
      "\n",
      "Best Leaf Size: 50 | Best MAE: 1.6066773766058149\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "max_leaf_sizes = [5, 10, 50, 100, 500]\n",
    "maes = []\n",
    "\n",
    "for leaf_size in max_leaf_sizes:\n",
    "    DT = DecisionTreeRegressor(random_state=7, max_leaf_nodes=leaf_size)\n",
    "    DT.fit(X_train, y_train)\n",
    "    mae = mean_absolute_error(y_test, DT.predict(X_test))\n",
    "    print(f'Max Leafs: {leaf_size} | MAE: {mae}')\n",
    "\n",
    "    maes.append(mae)\n",
    "\n",
    "best_leaf_size = max_leaf_sizes[np.argmin(maes)]\n",
    "best_mae = np.min(maes)\n",
    "print()\n",
    "print(f'Best Leaf Size: {best_leaf_size} | Best MAE: {best_mae}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.31 %\n"
     ]
    }
   ],
   "source": [
    "relative_error = round(best_mae/average_present_price *100, 2)\n",
    "print(relative_error, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the error has slightly decreased. In some cases, a 1% improvement may be something to party over. But, in our case, that is still some things we can do to further improve this model.\n",
    "\n",
    "### Random Forests\n",
    "\n",
    "The Ensemble theory says (and proves) that, if you properly join a group of more than one model with different parameters (or, rather, hyperparameters, if you shall) and use them to get a joint result, you will **always** get a better performance than with just one model (at least that is what the theory says). Random Forests are an Ensemble application with just Decision Trees as building blocks for a greater joint model. It creates a large number of models and uses them in conjunction to predict our label and, in theory, it should work best than even the better performing single Decision Tree. We will use Scikit-learns RandomForestRegressor class for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.217540000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "RF = RandomForestRegressor(random_state=7)\n",
    "RF.fit(X_train, y_train)\n",
    "mae_rf = mean_absolute_error(y_test, RF.predict(X_test))\n",
    "print(mae_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.15 %\n"
     ]
    }
   ],
   "source": [
    "relative_error = round(mae_rf/average_present_price *100, 2)\n",
    "print(relative_error, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the result is clearly better than the one we had just a moment ago. Is it good yet, probably not. Is it enough? As I've said, it depends on the scenario. Will we try to improve it further? Not now at least. We have used here everything we have learng this far from that introductory Kaggle course. Spoiler: the next step may be encoding the categorical data and normalizing the numerical ones, in other words, feature engineering. But that will only come in another time. \n",
    "\n",
    "In any case, this is my quick tutorial/walkthrough on how to create your first Decision Tree Machine Learning algorithm to predict the price of used cars. The notebook file will be available for download on my GitHub [**here**](https://github.com/DouglasRFLeite/UsedCarsPricePrediction.git) alongside the dataset used. I hope this helped you in any way but really, as I always say, even if it didnât help you, it helped me tremendously so itâs worth it. See you soon!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "260d53f25ae0bf85bd6e3ec476b46d4eecc4d51e8d1a97900adb19c003316dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
